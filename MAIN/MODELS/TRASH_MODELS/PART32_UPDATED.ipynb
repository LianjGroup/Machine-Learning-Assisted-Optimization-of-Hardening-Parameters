{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0781\n",
      "Epoch [200/1000], Loss: 0.0685\n",
      "Epoch [300/1000], Loss: 0.0779\n",
      "Epoch [400/1000], Loss: 0.0684\n",
      "Epoch [500/1000], Loss: 0.0764\n",
      "Epoch [600/1000], Loss: 0.0866\n",
      "Epoch [700/1000], Loss: 0.0731\n",
      "Epoch [800/1000], Loss: 0.0680\n",
      "Epoch [900/1000], Loss: 0.0840\n",
      "Epoch [1000/1000], Loss: 0.0732\n",
      "Actual parameters:\n",
      "[0.5828233169459215, 0.4525214870042456, 0.015251652262328427, 0.9639393939393941, 0.9979869149471565, 0.356618017111223, 0.0938791973379046]\n",
      "Predicted parameters:\n",
      "[0.48677003383636475, 1063.31396484375, 0.04777658358216286, 0.49148795008659363, 1053.936279296875, 534.5250244140625, 487.7805480957031]\n",
      "\n",
      "Actual parameters:\n",
      "[0.925253336008829, 0.9702806254530392, 0.050432130147432065, 0.4000000000000001, 0.09843985908404629, 0.9554101660795168, 0.23424422708480383]\n",
      "Predicted parameters:\n",
      "[0.6574394106864929, 1428.7724609375, 0.0341230146586895, 0.5550711154937744, 812.8944091796875, 595.2460327148438, 352.29791259765625]\n",
      "\n",
      "Actual parameters:\n",
      "[0.5551319353867763, 0.527078802940872, 0.017590238942551815, 0.49858585858585874, 0.7536990437845998, 0.10548565676899849, 0.5515780982151859]\n",
      "Predicted parameters:\n",
      "[0.6399211287498474, 1556.1014404296875, 0.04473498463630676, 0.5423005819320679, 1166.8739013671875, 562.7879638671875, 447.2235107421875]\n",
      "\n",
      "Actual parameters:\n",
      "[0.4821912310625062, 0.2574298436367402, 0.4876461616675137, 0.2938383838383839, 0.7722194262707599, 0.15279315551082034, 0.09982857719068265]\n",
      "Predicted parameters:\n",
      "[0.44623976945877075, 798.0177001953125, 0.04577973857522011, 0.3929632008075714, 1160.4783935546875, 465.8468322753906, 552.5438842773438]\n",
      "\n",
      "Actual parameters:\n",
      "[0.6721179893649041, 0.7458838148493321, 0.31703101169293374, 0.726868686868687, 0.44368394564670355, 0.11182687468545548, 0.36815569224563877]\n",
      "Predicted parameters:\n",
      "[0.7054857611656189, 1444.7647705078125, 0.04463827237486839, 0.6097690463066101, 855.754150390625, 515.1438598632812, 433.3666076660156]\n",
      "\n",
      "Actual parameters:\n",
      "[0.8269288652553425, 0.6284560422491458, 0.9748856126080333, 0.6292929292929295, 0.0498238550578762, 0.11524911927528939, 0.7876373903398204]\n",
      "Predicted parameters:\n",
      "[0.7405626773834229, 1378.7188720703125, 0.04625110328197479, 0.6382845044136047, 762.8235473632812, 493.8206787109375, 434.00006103515625]\n",
      "\n",
      "Actual parameters:\n",
      "[0.16394100531754785, 0.7198923060992026, 0.9262836807320798, 0.9415151515151517, 0.24640161046804226, 0.1455460493205838, 0.8417868306947665]\n",
      "Predicted parameters:\n",
      "[0.5923985838890076, 923.8529052734375, 0.0491914264857769, 0.5563580393791199, 773.006591796875, 481.56170654296875, 510.2596435546875]\n",
      "\n",
      "Actual parameters:\n",
      "[0.2295575398816092, 0.47934141037589306, 0.6544992374173865, 0.7216161616161617, 0.5536990437845999, 0.8720684448917966, 0.28335182010688714]\n",
      "Predicted parameters:\n",
      "[0.33612966537475586, 974.7797241210938, 0.04843386635184288, 0.4090556204319, 1380.8094482421875, 540.2018432617188, 517.8189086914062]\n",
      "\n",
      "Actual parameters:\n",
      "[0.5828233169459215, 0.4525214870042456, 0.015251652262328427, 0.9639393939393941, 0.9979869149471565, 0.356618017111223, 0.0938791973379046]\n",
      "Predicted parameters:\n",
      "[0.5727246403694153, 1361.1185302734375, 0.046897612512111664, 0.5143608450889587, 1213.6422119140625, 555.2075805664062, 476.7115478515625]\n",
      "\n",
      "Actual parameters:\n",
      "[0.33811578208086673, 0.48534741638189915, 0.40721911540416855, 0.7695959595959597, 0.07398087569199797, 0.10810266733769502, 0.11132398910960976]\n",
      "Predicted parameters:\n",
      "[0.7191997766494751, 787.5191650390625, 0.051783446222543716, 0.605162501335144, 713.1331176757812, 472.4221496582031, 453.20703125]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Load your data\n",
    "X_data = pd.read_csv(\"MODEL_DATA/NEWDATA/newData_combined_FD.csv\").values\n",
    "Y_data = pd.read_csv(\"MODEL_DATA/NEWDATA/newData_expanded_realHardParam.csv\").values\n",
    "\n",
    "# Data scaling\n",
    "input_scaler = MinMaxScaler()\n",
    "X_data_scaled = input_scaler.fit_transform(X_data)\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "Y_data_scaled = target_scaler.fit_transform(Y_data)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the updated neural network model\n",
    "class UpdatedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, lambda_reg):\n",
    "        super(UpdatedNeuralNetwork, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_sizes[i]))\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def l2_regularization(self):\n",
    "        l2_reg = 0.0\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                l2_reg += torch.norm(layer.weight)\n",
    "        return self.lambda_reg * l2_reg\n",
    "\n",
    "# Custom loss function with regularization\n",
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self, lambda_reg):\n",
    "        super(CustomMSELoss, self).__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, outputs, targets, model):\n",
    "        mse_loss = nn.MSELoss()(outputs, targets)\n",
    "        return mse_loss + model.l2_regularization()\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 128, 64]\n",
    "output_size = Y_train.shape[1]\n",
    "lambda_reg = 0.001\n",
    "\n",
    "# Instantiate the updated model\n",
    "model = UpdatedNeuralNetwork(input_size, hidden_sizes, output_size, lambda_reg)\n",
    "criterion = CustomMSELoss(lambda_reg)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets, model)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Optional: Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_inputs = torch.tensor(X_val, dtype=torch.float32)\n",
    "    val_outputs = model(val_inputs)\n",
    "    val_predictions = target_scaler.inverse_transform(val_outputs.numpy())\n",
    "\n",
    "# Print and visualize results for a few samples\n",
    "for i in range(10):\n",
    "    print(f'Actual parameters:')\n",
    "    print(Y_val[i * 101].tolist())\n",
    "\n",
    "    print(f'Predicted parameters:')\n",
    "    print(val_predictions[i * 101].tolist())\n",
    "    print()\n",
    "\n",
    "# Visualize 'c1' to 'c7' values in a single graph for one sample\n",
    "param_names = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7']\n",
    "param_values = val_predictions[0, :7]\n",
    "\n",
    "plt.bar(np.arange(len(param_names)), param_values, width=0.2)\n",
    "plt.xlabel('Parameters (c1 to c7)')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Predicted Hardening Parameters')\n",
    "plt.xticks(np.arange(len(param_names)), param_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = np.where((val_predictions[:, 0] >= 2) & (val_predictions[:, 0] <= 3.5))[0]\n",
    "filtered_predictions = val_predictions[filtered_indices]\n",
    "\n",
    "for i in range(len(filtered_indices)):\n",
    "    idx = filtered_indices[i]\n",
    "    print(f'Actual parameters for filtered sample {i + 1}:')\n",
    "    print(Y_val[idx * 101].tolist())\n",
    "\n",
    "    print(f'Predicted parameters for filtered sample {i + 1}:')\n",
    "    print(filtered_predictions[i].tolist())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0682\n",
      "Epoch [200/1000], Loss: 0.0518\n",
      "Epoch [300/1000], Loss: 0.0555\n",
      "Epoch [400/1000], Loss: 0.0551\n",
      "Epoch [500/1000], Loss: 0.0421\n",
      "Epoch [600/1000], Loss: 0.0396\n",
      "Epoch [700/1000], Loss: 0.0396\n",
      "Epoch [800/1000], Loss: 0.0435\n",
      "Epoch [900/1000], Loss: 0.0447\n",
      "Epoch [1000/1000], Loss: 0.0344\n",
      "c1: Predicted = 5.14e-01, Ideal = 5.00e-01, Close = 92.59%\n",
      "c2: Predicted = 1.33e+03, Ideal = 1.30e+03, Close = 94.96%\n",
      "c3: Predicted = 2.34e-14, Ideal = 2.30e-14, Close = 88.40%\n",
      "c4: Predicted = 7.19e-02, Ideal = 7.50e-02, Close = 91.52%\n",
      "c5: Predicted = 7.44e+02, Ideal = 7.73e+02, Close = 91.59%\n",
      "c6: Predicted = 1.02e+03, Ideal = 1.04e+03, Close = 93.06%\n",
      "c7: Predicted = 7.76e+01, Ideal = 7.39e+01, Close = 92.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Define ideal parameters\n",
    "ideal_params = {\n",
    "    'c1': 0.5,\n",
    "    'c2': 1300,\n",
    "    'c3': 2.3e-14,\n",
    "    'c4': 0.075,\n",
    "    'c5': 773.18,\n",
    "    'c6': 1039.37,\n",
    "    'c7': 73.94\n",
    "}\n",
    "\n",
    "# Load the data\n",
    "x_data_path = 'MODEL_DATA/NEWDATA/newData_combined_FD.csv'  \n",
    "y_data_path = 'MODEL_DATA/NEWDATA/newData_expanded_realHardParam.csv' \n",
    "\n",
    "x_data = pd.read_csv(x_data_path)\n",
    "y_data = pd.read_csv(y_data_path)\n",
    "\n",
    "# Use a subset of the data for faster training\n",
    "subset_percentage = 0.99\n",
    "x_data_subset, _, y_data_subset, _ = train_test_split(x_data, y_data, test_size=1 - subset_percentage, random_state=42)\n",
    "\n",
    "# Data scaling\n",
    "input_scaler = MinMaxScaler()\n",
    "X_data_scaled = input_scaler.fit_transform(x_data_subset)\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "Y_data_scaled = target_scaler.fit_transform(y_data_subset)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 128, 64]\n",
    "output_size = Y_train.shape[1]\n",
    "percentage_range=(88,95)\n",
    "# Instantiate the model\n",
    "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_val_tensor)\n",
    "    # Inverse transform to get the predictions in the original scale\n",
    "    predictions_np = predictions.numpy()\n",
    "    predicted_parameters = target_scaler.inverse_transform(predictions_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0619\n",
      "Epoch [200/1000], Loss: 0.0592\n",
      "Epoch [300/1000], Loss: 0.0445\n",
      "Epoch [400/1000], Loss: 0.0529\n",
      "Epoch [500/1000], Loss: 0.0491\n",
      "Epoch [600/1000], Loss: 0.0518\n",
      "Epoch [700/1000], Loss: 0.0408\n",
      "Epoch [800/1000], Loss: 0.0397\n",
      "Epoch [900/1000], Loss: 0.0356\n",
      "Epoch [1000/1000], Loss: 0.0362\n",
      "[[6.5960956e-01 1.2167325e+03 4.3059833e-02 ... 1.1499620e+03\n",
      "  2.6903714e+02 4.8778537e+02]\n",
      " [5.4969174e-01 9.6498383e+02 4.8535421e-02 ... 8.5773663e+02\n",
      "  5.9072540e+02 5.4770435e+02]\n",
      " [1.3317360e-01 9.4420502e+02 7.7501602e-02 ... 1.8400776e+03\n",
      "  9.2035193e+02 2.2355586e+02]\n",
      " ...\n",
      " [7.1354121e-01 1.1241709e+03 4.9105518e-02 ... 7.6527557e+02\n",
      "  3.3871411e+02 4.3495676e+02]\n",
      " [2.1795306e-01 8.7754144e+02 6.2281080e-03 ... 1.1311980e+03\n",
      "  8.1119800e+02 9.2545056e+02]\n",
      " [5.3359616e-01 1.0375637e+03 3.9980307e-02 ... 9.7916888e+02\n",
      "  4.2759869e+02 3.6603665e+02]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data\n",
    "x_data_path = 'MODEL_DATA/NEWDATA/newData_combined_FD.csv'  \n",
    "y_data_path = 'MODEL_DATA/NEWDATA/newData_expanded_realHardParam.csv' \n",
    "\n",
    "x_data = pd.read_csv(x_data_path)\n",
    "y_data = pd.read_csv(y_data_path)\n",
    "\n",
    "# Use a subset of the data for faster training\n",
    "subset_percentage = 0.99\n",
    "x_data_subset, _, y_data_subset, _ = train_test_split(x_data, y_data, test_size=1 - subset_percentage, random_state=42)\n",
    "\n",
    "# Data scaling\n",
    "input_scaler = MinMaxScaler()\n",
    "X_data_scaled = input_scaler.fit_transform(x_data_subset)\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "Y_data_scaled = target_scaler.fit_transform(y_data_subset)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [128, 128, 64]\n",
    "output_size = Y_train.shape[1]\n",
    "percentage_range=(88,95)\n",
    "# Instantiate the model\n",
    "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()  # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_val_tensor)\n",
    "    # Inverse transform to get the predictions in the original scale\n",
    "    predictions_np = predictions.numpy()\n",
    "    predicted_parameters = target_scaler.inverse_transform(predictions_np)\n",
    "\n",
    "print(predicted_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
