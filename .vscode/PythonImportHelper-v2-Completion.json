[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "NeuralNetRegressor",
        "importPath": "skorch",
        "description": "skorch",
        "isExtraImport": true,
        "detail": "skorch",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "skorch.callbacks",
        "description": "skorch.callbacks",
        "isExtraImport": true,
        "detail": "skorch.callbacks",
        "documentation": {}
    },
    {
        "label": "NeuralNetwork",
        "kind": 6,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "class NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size1)\n        self.relu1 = nn.LeakyReLU(negative_slope=0.01)\n        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n        self.relu2 = nn.LeakyReLU(negative_slope=0.01)\n        self.fc3 = nn.Linear(hidden_size2, hidden_size3)  # New hidden layer\n        self.relu3 = nn.LeakyReLU(negative_slope=0.01)     # New activation function\n        self.fc4 = nn.Linear(hidden_size3, output_size)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "x_data_file",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "x_data_file = \"MODEL_DATA/NEWDATA/newData_combined_FD.csv\"\ny_data_file = \"MODEL_DATA/NEWDATA/newData_expanded_realHardParam.csv\"\nx_data = pd.read_csv(x_data_file)\ny_data = pd.read_csv(y_data_file)\n# Split the data into X (input features) and Y (target - c-parameters)\nX_data = x_data.values.astype(np.float32)\nY_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "y_data_file",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "y_data_file = \"MODEL_DATA/NEWDATA/newData_expanded_realHardParam.csv\"\nx_data = pd.read_csv(x_data_file)\ny_data = pd.read_csv(y_data_file)\n# Split the data into X (input features) and Y (target - c-parameters)\nX_data = x_data.values.astype(np.float32)\nY_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "x_data",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "x_data = pd.read_csv(x_data_file)\ny_data = pd.read_csv(y_data_file)\n# Split the data into X (input features) and Y (target - c-parameters)\nX_data = x_data.values.astype(np.float32)\nY_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "y_data",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "y_data = pd.read_csv(y_data_file)\n# Split the data into X (input features) and Y (target - c-parameters)\nX_data = x_data.values.astype(np.float32)\nY_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "X_data",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "X_data = x_data.values.astype(np.float32)\nY_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "Y_data",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "Y_data = y_data.values.astype(np.float32)\n# Create Min-Max scalers for input data and target values\ninput_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model\nclass NeuralNetwork(nn.Module):",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "input_scaler",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "input_scaler = MinMaxScaler()\nX_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n        super(NeuralNetwork, self).__init__()",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "X_data_scaled",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "X_data_scaled = input_scaler.fit_transform(X_data)\ntarget_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size1)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "target_scaler",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "target_scaler = MinMaxScaler()\nY_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size1)\n        self.relu1 = nn.LeakyReLU(negative_slope=0.01)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "Y_data_scaled",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "Y_data_scaled = target_scaler.fit_transform(Y_data)\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, Y_data_scaled, test_size=0.2, random_state=42)\n# Define a custom neural network model\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n        super(NeuralNetwork, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size1)\n        self.relu1 = nn.LeakyReLU(negative_slope=0.01)\n        self.fc2 = nn.Linear(hidden_size1, hidden_size2)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "net",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "net = NeuralNetRegressor(\n    module=NeuralNetwork,\n    module__input_size=X_data.shape[1],\n    module__hidden_size1=256,\n    module__hidden_size2=256,\n    module__hidden_size3=128,   # New hidden layer size\n    module__output_size=Y_data.shape[1],\n    criterion=nn.MSELoss,\n    optimizer=optim.Adam,\n    optimizer__lr=0.0005,",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "history",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "history = net.fit(X_train, y_train)\n# Extract the training and validation losses from the history\ntrain_losses = history.history[:, 'train_loss']\nvalid_losses = history.history[:, 'valid_loss']\n# Evaluate the model on the test set\ny_pred = net.predict(X_test)\n# Inverse scale the predictions to the original range\ny_pred_original = target_scaler.inverse_transform(y_pred)\ny_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "train_losses",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "train_losses = history.history[:, 'train_loss']\nvalid_losses = history.history[:, 'valid_loss']\n# Evaluate the model on the test set\ny_pred = net.predict(X_test)\n# Inverse scale the predictions to the original range\ny_pred_original = target_scaler.inverse_transform(y_pred)\ny_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "valid_losses",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "valid_losses = history.history[:, 'valid_loss']\n# Evaluate the model on the test set\ny_pred = net.predict(X_test)\n# Inverse scale the predictions to the original range\ny_pred_original = target_scaler.inverse_transform(y_pred)\ny_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "y_pred",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "y_pred = net.predict(X_test)\n# Inverse scale the predictions to the original range\ny_pred_original = target_scaler.inverse_transform(y_pred)\ny_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "y_pred_original",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "y_pred_original = target_scaler.inverse_transform(y_pred)\ny_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')\nprint(f'R-squared (R2) Score: {r2:.4f}')\n# Save the trained model",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "y_test_original",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "y_test_original = target_scaler.inverse_transform(y_test)\n# Calculate evaluation metrics\nmae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')\nprint(f'R-squared (R2) Score: {r2:.4f}')\n# Save the trained model\ntorch.save(net.module_.state_dict(), 'trained_model.pth')",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "mae",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "mae = mean_absolute_error(y_test_original, y_pred_original)\nmse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')\nprint(f'R-squared (R2) Score: {r2:.4f}')\n# Save the trained model\ntorch.save(net.module_.state_dict(), 'trained_model.pth')\n# Load the trained model for prediction\nnet.module_.load_state_dict(torch.load('trained_model.pth'))",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "mse = mean_squared_error(y_test_original, y_pred_original)\nr2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')\nprint(f'R-squared (R2) Score: {r2:.4f}')\n# Save the trained model\ntorch.save(net.module_.state_dict(), 'trained_model.pth')\n# Load the trained model for prediction\nnet.module_.load_state_dict(torch.load('trained_model.pth'))\nnet.module_.eval()",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "r2",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "r2 = r2_score(y_test_original, y_pred_original)\nprint(f'Mean Absolute Error: {mae:.4f}')\nprint(f'Mean Squared Error: {mse:.4f}')\nprint(f'R-squared (R2) Score: {r2:.4f}')\n# Save the trained model\ntorch.save(net.module_.state_dict(), 'trained_model.pth')\n# Load the trained model for prediction\nnet.module_.load_state_dict(torch.load('trained_model.pth'))\nnet.module_.eval()\n# Example prediction for a single input (you can replace this with your data)",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "X_example",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "X_example = X_test[0]\nX_example_tensor = torch.tensor(X_example, dtype=torch.float32)\nwith torch.no_grad():\n    prediction = net.module_(X_example_tensor.unsqueeze(0))  # Unsqueeze to add batch dimension\n# Inverse scale the prediction to the original range\nprediction_original = target_scaler.inverse_transform(prediction.numpy())\n# Print the predicted 'c-parameters'\npredicted_parameters = prediction_original[0].tolist()\nprint(f'Predicted c-parameters:')\nprint(prediction_original[0].tolist())",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "X_example_tensor",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "X_example_tensor = torch.tensor(X_example, dtype=torch.float32)\nwith torch.no_grad():\n    prediction = net.module_(X_example_tensor.unsqueeze(0))  # Unsqueeze to add batch dimension\n# Inverse scale the prediction to the original range\nprediction_original = target_scaler.inverse_transform(prediction.numpy())\n# Print the predicted 'c-parameters'\npredicted_parameters = prediction_original[0].tolist()\nprint(f'Predicted c-parameters:')\nprint(prediction_original[0].tolist())\n# val error usually around 0.05",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "prediction_original",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "prediction_original = target_scaler.inverse_transform(prediction.numpy())\n# Print the predicted 'c-parameters'\npredicted_parameters = prediction_original[0].tolist()\nprint(f'Predicted c-parameters:')\nprint(prediction_original[0].tolist())\n# val error usually around 0.05\n# r-squared value usually around 0.5",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    },
    {
        "label": "predicted_parameters",
        "kind": 5,
        "importPath": "MAIN.MODELS.FINAL_MODEL",
        "description": "MAIN.MODELS.FINAL_MODEL",
        "peekOfCode": "predicted_parameters = prediction_original[0].tolist()\nprint(f'Predicted c-parameters:')\nprint(prediction_original[0].tolist())\n# val error usually around 0.05\n# r-squared value usually around 0.5",
        "detail": "MAIN.MODELS.FINAL_MODEL",
        "documentation": {}
    }
]